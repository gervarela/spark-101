{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark on Tour\n",
    "## Segmentación automática de usuarios\n",
    "\n",
    "A partir de la información de perfil de usuarios por género de película generada en ejemplos anterires, vamos a utilizar un algoritmo de clusterización automática mendiante ML no supervisada para analizar patrones de comportamientos similares en nuestros usuarios.\n",
    "\n",
    "La segmentación mediante ML nos permitira buscar este tipo relaciones/patrones de forma automática y basada en los propios datos, minizando sesgos y subjetividades, y posibilitando el descubrimiento de nueva información a partir de los datos en forma de relaciones no conocidas en el comportamiento de los usuarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos librerías, definimos esquemas e inicializamos la sesión Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "ratingSchema = StructType([\n",
    "    StructField(\"user\", IntegerType()),\n",
    "    StructField(\"movie\", IntegerType()),\n",
    "    StructField(\"rating\", FloatType())\n",
    "])\n",
    "\n",
    "movieSchema = StructType([\n",
    "    StructField(\"movie\", IntegerType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"genres\", StringType())\n",
    "])\n",
    "\n",
    "\n",
    "#setup spark session\n",
    "sparkSession = (SparkSession.builder\n",
    "                .appName(\"Introducción API estructurada\")\n",
    "                .master(\"local[*]\")\n",
    "                .config(\"spark.scheduler.mode\", \"FAIR\")\n",
    "                .getOrCreate())\n",
    "sparkSession.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leemos el dataset de ratings usuario / película"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = sparkSession.read.csv(\"/tmp/movielens/ratings.csv\", schema=ratingSchema, header=True)\n",
    "ratings.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "(training, test) = ratings.randomSplit([0.8, 0.2])\n",
    "als = ALS(maxIter=20, rank=10, regParam=0.01, userCol=\"user\", itemCol=\"movie\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\", implicitPrefs=True)\n",
    "model = als.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leemos el dataset de películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = sparkSession.read.csv(\"/tmp/movielens/movies.csv\", schema=movieSchema, header=True)\n",
    "movies.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformamos el dataset de películas para asociar cada película con cada uno de sus genéros \n",
    "\n",
    "El resultado es un dataset con N filas por película, tantas como género."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.select(\"movie\", \"title\", split(\"genres\", \"\\|\").alias(\"genres\"))\n",
    "movies = movies.select(\"movie\", \"title\", explode(\"genres\").alias(\"genre\"))\n",
    "movies.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mezclamos movies y ratings\n",
    "Enriquecemos la información de ratings con los géneros de cada película, y nos quedaos con un dataframe donde cada película aparece en varias filas, una por cada género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRatings = ratings.join(movies, \"movie\", \"left_outer\")\n",
    "movieRatings.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregamos por género y usuario\n",
    "Calculamos indicadores de interés de un usuario en cada género, como el nº total de películas votadas, la media de rating, el máximo rating y el mínimo rating.\n",
    "\n",
    "Nuestro objetivo es calcular un perfil de usuario por género, por lo que no nos interesan las películas individuales, sino la agregación de los ratings por género para cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRatingsGenres = movieRatings.groupBy(\"user\", \"genre\") \\\n",
    "            .agg( \\\n",
    "                count(\"rating\").alias(\"num_ratings\"),  \\\n",
    "                avg(\"rating\").alias(\"avg_rating\"), \\\n",
    "                min(\"rating\").alias(\"min_rating\"), \\\n",
    "                max(\"rating\").alias(\"max_rating\")) \\\n",
    "            .sort(asc(\"user\"))\n",
    "userRatingsGenres.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos el dataset final de perfil de usuario\n",
    "Ya tenemos la información que queríamos, pero no en la forma que necesitamos para, por ejemplo entrenar un modelo de ML y hacer segmentación de usuarios o predicción de cuanto le va a gusar una película en función de los géneros a los que pertenece.\n",
    "\n",
    "Necesitamos generar una única fila por cada usuario que represente el perfil del usuario, y por tanto sus 'gustos' con respecto a los diverso géneros de película."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userRatingProfile = userRatingsGenres.groupBy(\"user\") \\\n",
    "                .pivot(\"genre\") \\\n",
    "                .agg(sum(\"avg_rating\").alias(\"rating\"), sum(\"num_ratings\").alias(\"num\"))\n",
    "userRatingProfile.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredProfiles = userRatingProfile \\\n",
    "                .select(\"user\", \"Action_num\", \"Adventure_num\", \"Animation_num\", \"Children_num\", \"Romance_num\") \\\n",
    "                .na.drop()\n",
    "filteredProfiles.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureAssembler = VectorAssembler(\n",
    "        inputCols=[\"Action_num\", \"Adventure_num\", \"Animation_num\", \"Children_num\", \"Romance_num\"],\n",
    "        outputCol=\"features\")\n",
    "\n",
    "clusteringProfiles = featureAssembler.setHandleInvalid(\"keep\").transform(filteredProfiles).select(\"user\", \"features\")\n",
    "clusteringProfiles.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train K-Means and use elbow method (graphically) to decide the best K\n",
    "evaluator = ClusteringEvaluator()\n",
    "kIndex = []\n",
    "sseError = []\n",
    "for k in range(2, 12):\n",
    "    kmeans = KMeans().setK(k)\n",
    "    kmeansModel = kmeans.fit(clusteringProfiles)\n",
    "    predictions = kmeansModel.transform(clusteringProfiles)\n",
    "    silhouette = evaluator.evaluate(predictions)\n",
    "    sse = kmeansModel.computeCost(clusteringProfiles)\n",
    "    print(\"K = \", k, \" | Silhouette = \", str(silhouette), \" | SSE = \", sse)\n",
    "    kIndex.append(k)\n",
    "    sseError.append(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show results for elbow-method\n",
    "import plotly.express as px\n",
    "fig = px.line(x=kIndex, y=sseError)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K=7 seems the best option, train the segmentation model\n",
    "kmeans = KMeans().setK(6)\n",
    "kmeansModel = kmeans.fit(clusteringProfiles)\n",
    "\n",
    "#predict the cluster of each user\n",
    "predictions = kmeansModel.transform(clusteringProfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedProfiles = filteredProfiles.join(predictions, \"user\", \"left_outer\").drop(\"features\")\n",
    "predictedProfiles.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize clustering results\n",
    "fig = px.scatter(predictedProfiles.toPandas(), x=\"Action_num\", y=\"Adventure_num\", color=\"prediction\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize clustering results\n",
    "fig = px.scatter_matrix(predictedProfiles.toPandas(), dimensions=[\"Action_num\", \"Adventure_num\", \"Animation_num\", \"Children_num\", \"Romance_num\"], color=\"prediction\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize clustering results\n",
    "fig = px.scatter(predictedProfiles.toPandas(), x=\"Children_num\", y=\"Romance_num\", color=\"prediction\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize clustering results\n",
    "fig = px.scatter(predictedProfiles.toPandas(), x=\"Children_num\", y=\"Animation_num\", color=\"prediction\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate statistics of each cluster+gener\n",
    "result1 = predictedProfiles.select(\"user\", \"prediction\", \"Action_num\", \"Adventure_num\", \"Animation_num\", \"Children_num\", \"Romance_num\") \\\n",
    "    .groupBy(\"prediction\") \\\n",
    "    .agg(expr(\"count(*) as count\"), \\\n",
    "         expr(\"avg(Action_num) as avgAct\"), expr(\"min(Action_num) as minAct\"), expr(\"max(Action_num) as maxAct\"), \\\n",
    "         expr(\"avg(Adventure_num) as avgAdv\"), expr(\"min(Adventure_num) as minAdv\"), expr(\"max(Adventure_num) as maxAdv\"), \\\n",
    "         expr(\"avg(Animation_num) as avgAni\"), expr(\"min(Animation_num) as minAni\"), expr(\"max(Animation_num) as maxAni\"), \\\n",
    "         expr(\"avg(Children_num) as avgChild\"), expr(\"min(Children_num) as minChild\"), expr(\"max(Children_num) as maxChild\"), \\\n",
    "         expr(\"avg(Romance_num) as avgRom\"), expr(\"min(Romance_num) as minRom\"), expr(\"max(Romance_num) as maxRom\")) \\\n",
    "    .sort(asc(\"prediction\"))\n",
    "\n",
    "result1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
